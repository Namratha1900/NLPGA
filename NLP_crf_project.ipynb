{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-11-01T15:20:08.294565Z","iopub.status.busy":"2023-11-01T15:20:08.294195Z","iopub.status.idle":"2023-11-01T15:20:08.705237Z","shell.execute_reply":"2023-11-01T15:20:08.704021Z","shell.execute_reply.started":"2023-11-01T15:20:08.294536Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd \n","\n","\n","import os\n","for dirname, _, filenames in os.walk('input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T15:20:08.708057Z","iopub.status.busy":"2023-11-01T15:20:08.707471Z","iopub.status.idle":"2023-11-01T15:20:25.767053Z","shell.execute_reply":"2023-11-01T15:20:25.765763Z","shell.execute_reply.started":"2023-11-01T15:20:08.708018Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: pytorch-crf in c:\\users\\victor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.7.2)\n","Requirement already satisfied: seqeval in c:\\users\\victor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.14.0 in c:\\users\\victor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seqeval) (1.26.2)\n","Requirement already satisfied: scikit-learn>=0.21.3 in c:\\users\\victor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from seqeval) (1.3.2)\n","Requirement already satisfied: scipy>=1.5.0 in c:\\users\\victor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in c:\\users\\victor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\victor\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n"]}],"source":["! pip install pytorch-crf seqeval"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T15:20:25.769331Z","iopub.status.busy":"2023-11-01T15:20:25.768987Z","iopub.status.idle":"2023-11-01T15:20:36.942489Z","shell.execute_reply":"2023-11-01T15:20:36.941582Z","shell.execute_reply.started":"2023-11-01T15:20:25.769303Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torchcrf import CRF\n","from tqdm import tqdm\n","import transformers\n","\n","import pandas as pd\n","import numpy as np\n","import joblib\n","\n","from sklearn import preprocessing\n","from sklearn import model_selection\n","\n","from transformers import AdamW\n","from transformers import get_linear_schedule_with_warmup\n","from datasets import load_dataset\n","from seqeval.metrics import classification_report as seq_classification_report, accuracy_score as seq_accuracy_score, f1_score as seq_f1_score\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T15:20:36.946427Z","iopub.status.busy":"2023-11-01T15:20:36.945649Z","iopub.status.idle":"2023-11-01T15:20:38.083912Z","shell.execute_reply":"2023-11-01T15:20:38.082767Z","shell.execute_reply.started":"2023-11-01T15:20:36.94639Z"},"trusted":true},"outputs":[],"source":["class Config:\n","    def __init__(self):\n","        self.MAX_LEN = 128\n","        self.TRAIN_BATCH_SIZE = 16\n","        self.VALID_BATCH_SIZE = 8\n","        self.EPOCHS = 15\n","        self.BASE_MODEL_PATH = \"bert-large-cased\"\n","        self.MODEL_PATH = \"./model.pt\"\n","#         self.TRAINING_FILE = \"/input/conll003-englishversion/train.txt\"\n","        self.TOKENIZER = transformers.BertTokenizer.from_pretrained(\n","                self.BASE_MODEL_PATH,\n","                do_lower_case=False\n","            )\n","config = Config()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T15:20:38.085625Z","iopub.status.busy":"2023-11-01T15:20:38.085321Z","iopub.status.idle":"2023-11-01T15:20:38.101891Z","shell.execute_reply":"2023-11-01T15:20:38.100557Z","shell.execute_reply.started":"2023-11-01T15:20:38.085599Z"},"trusted":true},"outputs":[],"source":["class EntityDataset:\n","    def __init__(self, texts, tags):\n","        # Ensure the length of texts is equal to the length of tags\n","        assert len(texts) == len(tags)\n","        self.texts = texts\n","        self.tags = tags\n","\n","    def __len__(self):\n","        # Return the length of the dataset\n","        return len(self.texts)\n","\n","    def __getitem__(self, item):\n","        # Get text and tags for a specific item\n","        text = self.texts[item]\n","        tags = self.tags[item]\n","\n","        # Initialize empty lists and variables\n","        ids = []\n","        target_tag = tags\n","        valid_mask = []\n","\n","        # Tokenize each word in the text\n","        for i, s in enumerate(text):\n","            inputs = config.TOKENIZER.tokenize(s)\n","            # Create a valid mask for each token\n","            valid_mask.extend([1] + [0] * (len(inputs) - 1))\n","            ids.extend(inputs)\n","\n","        # Convert tokens to IDs\n","        ids = config.TOKENIZER.convert_tokens_to_ids(ids)\n","        ids = ids[:config.MAX_LEN - 2]\n","        valid_mask = valid_mask[:config.MAX_LEN - 2]\n","        target_tag = target_tag[:config.MAX_LEN - 2]\n","\n","        # Initialize mask and mask_crf\n","        mask = [1] * len(ids)\n","        mask_crf = [1] * len(ids)\n","\n","        # Add special tokens\n","        ids = [101] + ids + [102]\n","        target_tag = [0] + target_tag + [0]\n","        valid_mask = [1] + valid_mask + [1]\n","        mask = [0] + mask + [0]\n","        mask_crf = [1] + mask_crf + [1]\n","\n","        # Initialize token_type_ids\n","        token_type_ids = [0] * config.MAX_LEN\n","\n","        # Padding\n","        padding_len = config.MAX_LEN - len(ids)\n","        ids = ids + [0] * padding_len\n","        mask = mask + [0] * padding_len\n","        mask_crf = mask_crf + [0] * padding_len\n","        valid_mask = valid_mask + [0] * padding_len\n","\n","        # Other padding for target_tag\n","        other_padding_len = config.MAX_LEN - len(target_tag)\n","        target_tag = target_tag + [0] * other_padding_len\n","\n","        # Assertion checks\n","        assert len(ids) == config.MAX_LEN\n","        assert len(mask) == config.MAX_LEN\n","        assert len(mask_crf) == config.MAX_LEN\n","        assert len(token_type_ids) == config.MAX_LEN\n","        assert len(target_tag) == config.MAX_LEN\n","        assert len(valid_mask) == config.MAX_LEN\n","\n","        # Return a dictionary containing relevant tensors\n","        return {\n","            \"ids\": torch.tensor(ids, dtype=torch.long),\n","            \"mask\": torch.tensor(mask, dtype=torch.long),\n","            \"mask_crf\": torch.tensor(mask_crf, dtype=torch.long),\n","            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n","            \"target_tag\": torch.tensor(target_tag, dtype=torch.long),\n","            \"valid_mask\": torch.tensor(valid_mask, dtype=torch.long)\n","        }\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class CRF(nn.Module):\n","    def __init__(self, num_tags):\n","        super(CRF, self).__init__()\n","        self.num_tags = num_tags\n","\n","        # Transition scores, where transitions[i, j] is the score of transitioning from tag i to tag j.\n","        self.transitions = nn.Parameter(torch.randn(num_tags, num_tags))\n","\n","    def forward(self, emissions, tags):\n","        \"\"\"\n","        Calculate the negative log likelihood of a sequence of tags given emission scores.\n","\n","        Args:\n","            emissions (torch.Tensor): Emission score for each tag at each timestep, shape (seq_len, num_tags).\n","            tags (torch.LongTensor): Sequence of tags, shape (seq_len,).\n","\n","        Returns:\n","            torch.Tensor: Negative log likelihood, a scalar.\n","        \"\"\"\n","        seq_len = emissions.size(0)\n","\n","        # Calculate the score of the provided tags\n","        score = self.transitions[tags[:-1], tags[1:]].sum() + emissions[list(range(seq_len)), tags].sum()\n","\n","        # Calculate the sum of scores for all possible tag sequences\n","        all_scores = emissions[0, :] + self.transitions + emissions[1:, :].view(seq_len - 1, 1, -1)\n","        all_scores = all_scores.expand(seq_len - 1, -1, -1)\n","        all_scores = all_scores + emissions[2:, :].view(seq_len - 2, -1, 1)\n","        all_scores = all_scores.sum(dim=0)\n","\n","        # Calculate the log sum exp\n","        log_sum_exp = torch.logsumexp(all_scores, dim=1)\n","\n","        # Calculate the negative log likelihood\n","        return log_sum_exp - score\n","\n","    def viterbi_decode(self, emissions):\n","        \"\"\"\n","        Viterbi decoding to find the most likely sequence of tags given emission scores.\n","\n","        Args:\n","            emissions (torch.Tensor): Emission score for each tag at each timestep, shape (seq_len, num_tags).\n","\n","        Returns:\n","            torch.Tensor: Most likely sequence of tags, shape (seq_len,).\n","        \"\"\"\n","        seq_len = emissions.size(0)\n","\n","        # Initialize the viterbi variables\n","        viterbi_vars = emissions[0, :].unsqueeze(0)\n","        backpointers = []\n","\n","        # Forward pass\n","        for t in range(1, seq_len):\n","            viterbi_t = viterbi_vars[t - 1, :].view(-1, 1) + self.transitions + emissions[t, :].view(1, -1)\n","            max_score, best_path = viterbi_t.max(dim=0)\n","            viterbi_vars = torch.cat([viterbi_vars, max_score.unsqueeze(0)])\n","            backpointers.append(best_path)\n","\n","        # Backward pass to find the best path\n","        best_last_tag = torch.argmax(viterbi_vars[-1, :])\n","        best_path = [best_last_tag.item()]\n","\n","        for backpointer in reversed(backpointers):\n","            best_last_tag = backpointer[best_last_tag]\n","            best_path.append(best_last_tag.item())\n","\n","        return torch.tensor(list(reversed(best_path)))\n","\n","# Example usage:\n","num_tags = 5\n","crf = CRF(num_tags)\n","\n","# Dummy emissions and tags for demonstration purposes\n","emissions = torch.randn(10, num_tags)\n","tags = torch.tensor([2, 1, 4, 3, 2, 0, 1, 4, 3, 2])\n","\n","# Calculate negative log likelihood\n","neg_log_likelihood = crf(emissions, tags)\n","print(\"Negative Log Likelihood:\", neg_log_likelihood.item())\n","\n","# Viterbi decoding\n","best_path = crf.viterbi_decode(emissions)\n","print(\"Viterbi Decoding - Best Path:\", best_path.numpy())\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T15:20:38.103858Z","iopub.status.busy":"2023-11-01T15:20:38.103469Z","iopub.status.idle":"2023-11-01T15:20:38.120791Z","shell.execute_reply":"2023-11-01T15:20:38.119755Z","shell.execute_reply.started":"2023-11-01T15:20:38.103828Z"},"trusted":true},"outputs":[],"source":["from tqdm import tqdm\n","from sklearn.metrics import f1_score\n","from collections import defaultdict\n","\n","def train_fn(data_loader, model, optimizer, device, scheduler):\n","    model.train()\n","    final_loss = 0\n","    y_true_accumulator = []\n","    y_pred_accumulator = []\n","\n","    for data in tqdm(data_loader, total=len(data_loader)):\n","        # Move data to the specified device\n","        for k, v in data.items():\n","            data[k] = v.to(device)\n","\n","        # Zero out gradients\n","        optimizer.zero_grad()\n","\n","        # Forward pass\n","        tag, target_tag, mask, loss = model(**data)\n","\n","        # Mapping indices to tag labels\n","        map_dict = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'}\n","        mapped_target = [map_dict[item] for item in torch.flatten(mask * target_tag).detach().cpu().tolist()]\n","        mapped_output = [map_dict[item] for item in torch.flatten(mask * tag).detach().cpu().tolist()]\n","\n","        y_true_accumulator.append(mapped_target)\n","        y_pred_accumulator.append(mapped_output)\n","\n","        # Backward pass and optimization\n","        loss.backward()\n","        optimizer.step()\n","        scheduler.step()\n","\n","        # Accumulate loss\n","        final_loss += loss.item()\n","\n","    # Calculate average loss and F1 score\n","    avg_loss = final_loss / len(data_loader)\n","    f1 = f1_score(y_true_accumulator, y_pred_accumulator)\n","\n","    return avg_loss, f1\n","\n","def eval_fn(data_loader, model, device):\n","    model.eval()\n","    final_loss = 0\n","    y_true_accumulator = []\n","    y_pred_accumulator = []\n","\n","    for data in tqdm(data_loader, total=len(data_loader)):\n","        # Move data to the specified device\n","        for k, v in data.items():\n","            data[k] = v.to(device)\n","\n","        # Forward pass\n","        tag, target_tag, mask, loss = model(**data)\n","\n","        # Mapping indices to tag labels\n","        map_dict = {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'}\n","        mapped_target = [map_dict[item] for item in torch.flatten(mask * target_tag).detach().cpu().tolist()]\n","        mapped_output = [map_dict[item] for item in torch.flatten(mask * tag).detach().cpu().tolist()]\n","\n","        y_true_accumulator.append(mapped_target)\n","        y_pred_accumulator.append(mapped_output)\n","\n","        # Accumulate loss\n","        final_loss += loss.item()\n","\n","    # Calculate average loss and F1 score\n","    avg_loss = final_loss / len(data_loader)\n","    f1 = f1_score(y_true_accumulator, y_pred_accumulator)\n","\n","    return avg_loss, f1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T15:20:38.122581Z","iopub.status.busy":"2023-11-01T15:20:38.122233Z","iopub.status.idle":"2023-11-01T15:20:38.135928Z","shell.execute_reply":"2023-11-01T15:20:38.134992Z","shell.execute_reply.started":"2023-11-01T15:20:38.12255Z"},"trusted":true},"outputs":[],"source":["\n","class EntityModel(nn.Module):\n","    def __init__(self, num_tag):\n","        super(EntityModel, self).__init__()\n","        self.num_tag = num_tag\n","        # Load pre-trained BERT model\n","        self.bert = transformers.BertModel.from_pretrained(config.BASE_MODEL_PATH, return_dict=False)\n","        # Linear layer for tag prediction\n","        self.out_tag = nn.Linear(1024, self.num_tag)\n","        # Initialize bias for the 'O' tag\n","        self.out_tag.bias.data[0] = 6\n","        # Conditional Random Field (CRF) layer\n","        self.crf = CRF(self.num_tag, batch_first=True)\n","\n","    def forward(self, ids, mask, mask_crf, token_type_ids, target_tag, valid_mask):\n","        # BERT forward pass\n","        o1, _ = self.bert(ids, attention_mask=mask, token_type_ids=token_type_ids)\n","        # Linear layer for tag prediction\n","        emissions = self.out_tag(o1)\n","        # CRF calculations\n","        log_likelihood, sequence_of_tags = self.crf(emissions, target_tag, mask=mask_crf.bool(), reduction='mean'), self.crf.decode(emissions, mask=mask_crf.bool())\n","\n","        # Apply the 'valid_sequence_output' function\n","        tag, mask = valid_sequence_output(sequence_of_tags, valid_mask, mask)\n","\n","        # Calculate loss as negative log-likelihood\n","        loss = -1 * log_likelihood\n","\n","        return tag, target_tag, mask, loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T15:20:38.137946Z","iopub.status.busy":"2023-11-01T15:20:38.137625Z","iopub.status.idle":"2023-11-01T15:20:38.151077Z","shell.execute_reply":"2023-11-01T15:20:38.149987Z","shell.execute_reply.started":"2023-11-01T15:20:38.137919Z"},"trusted":true},"outputs":[],"source":["def valid_sequence_output(sequence_output, valid_mask, attention_mask): # convert token back to word\n","\n","    # batch_size, max_len, feat_dim = sequence_output.shape\n","    batch_size = len(sequence_output)\n","    max_len = config.MAX_LEN\n","    current_len = len(sequence_output[0])\n","    valid_output = torch.zeros(batch_size, max_len, dtype = torch.long,\n","                                device='cuda' if torch.cuda.is_available() else 'cpu')\n","    valid_attention_mask = torch.zeros(batch_size, max_len, dtype = torch.long,\n","                                device='cuda' if torch.cuda.is_available() else 'cpu')\n","\n","\n","    for i in range(batch_size):\n","        jj = -1\n","        for j in range(current_len):\n","            if valid_mask[i][j].item() == 1:\n","                jj += 1\n","                valid_output[i][jj] = sequence_output[i][j]*attention_mask[i][j]\n","                valid_attention_mask[i][jj] = attention_mask[i][j]\n","\n","    return valid_output, valid_attention_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T15:20:38.170454Z","iopub.status.busy":"2023-11-01T15:20:38.170067Z","iopub.status.idle":"2023-11-01T18:44:06.978125Z","shell.execute_reply":"2023-11-01T18:44:06.976847Z","shell.execute_reply.started":"2023-11-01T15:20:38.170416Z"},"trusted":true},"outputs":[],"source":["# Load the CoNLL-2003 dataset\n","dataset = load_dataset(\"conll2003\")\n","\n","# Create EntityDataset instances for training and validation\n","train_dataset = EntityDataset(texts=dataset['train']['tokens'], tags=dataset['train']['ner_tags'])\n","valid_dataset = EntityDataset(texts=dataset['validation']['tokens'], tags=dataset['validation']['ner_tags'])\n","\n","# Create DataLoader instances\n","train_data_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=config.TRAIN_BATCH_SIZE, num_workers=4)\n","valid_data_loader = torch.utils.data.DataLoader(valid_dataset, shuffle=True, batch_size=config.VALID_BATCH_SIZE, num_workers=1)\n","\n","# Set the device\n","device = torch.device(\"cuda\")\n","\n","# Define the tagset and create the EntityModel\n","tagset = {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n","model = EntityModel(num_tag=len(tagset))\n","model.to(device)\n","\n","# Define optimizer parameters\n","optimizer_parameters = [\n","    {\"params\": model.bert.parameters(), \"lr\": 5e-5},\n","    {\"params\": model.out_tag.parameters(), \"lr\": 1e-3},\n","    {\"params\": model.crf.parameters(), \"lr\": 1e-3},\n","]\n","\n","# Calculate the number of training steps\n","num_train_steps = int(dataset['train'].num_rows / config.TRAIN_BATCH_SIZE * config.EPOCHS)\n","\n","# Create AdamW optimizer and linear schedule with warmup\n","optimizer = AdamW(optimizer_parameters, weight_decay=0.01)\n","scheduler = get_linear_schedule_with_warmup(\n","    optimizer, num_warmup_steps=num_train_steps * 0.1, num_training_steps=num_train_steps\n",")\n","\n","# Initialize best_loss for model saving\n","best_loss = np.inf\n","\n","# Training loop\n","for epoch in range(config.EPOCHS):\n","    # Train the model\n","    train_loss, train_f1 = train_fn(train_data_loader, model, optimizer, device, scheduler)\n","    \n","    # Evaluate the model on the validation set\n","    val_loss, val_f1 = eval_fn(valid_data_loader, model, device)\n","    \n","    # Print training and validation metrics\n","    print(f\"Train loss = {train_loss} Valid loss = {val_loss} \")\n","    print(f\"Train f1_score = {train_f1} Valid f1_score = {val_f1} \")\n","    \n","    # Save the model if validation loss improves\n","    if val_loss < best_loss:\n","        torch.save(model.state_dict(), config.MODEL_PATH)\n","        best_loss = val_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T18:44:06.980458Z","iopub.status.busy":"2023-11-01T18:44:06.980053Z","iopub.status.idle":"2023-11-01T18:44:06.986746Z","shell.execute_reply":"2023-11-01T18:44:06.985599Z","shell.execute_reply.started":"2023-11-01T18:44:06.980423Z"},"trusted":true},"outputs":[],"source":["print(train_f1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T18:44:06.988459Z","iopub.status.busy":"2023-11-01T18:44:06.988173Z","iopub.status.idle":"2023-11-01T18:44:07.00673Z","shell.execute_reply":"2023-11-01T18:44:07.005833Z","shell.execute_reply.started":"2023-11-01T18:44:06.988434Z"},"trusted":true},"outputs":[],"source":["def test_fn(data_loader,model, device):\n","    model.eval()\n","    final_loss = 0\n","    y_true_accumulator = []\n","    y_pred_accumulator = []\n","    for data in tqdm(data_loader,total=len(data_loader)):\n","        for k,v in data.items():\n","            data[k] = v.to(device)\n","        tag, target_tag, mask, loss = model(**data)\n","#         y_true_accumulator.append(torch.flatten(mask*target_tag).detach().cpu().tolist())\n","#         y_pred_accumulator.append(torch.flatten(mask*tag).detach().cpu().tolist()) \n","        map_dict = {0 : 'O', 1 : 'B-PER', 2 : 'I-PER', 3 : 'B-ORG', 4 : 'I-ORG', 5 : 'B-LOC', 6 : 'I-LOC', 7 : 'B-MISC', 8 : 'I-MISC'}\n","        mapped_target = [map_dict[item] for item in torch.flatten(mask*target_tag).detach().cpu().tolist()]\n","        mapped_output = [map_dict[item] for item in torch.flatten(mask*tag).detach().cpu().tolist()]\n","        y_true_accumulator.append(mapped_target)\n","        y_pred_accumulator.append(mapped_output)   \n","        final_loss += loss.item()\n","        \n","    print(classification_report(y_true_accumulator, y_pred_accumulator, digits=2))\n","    return final_loss/len(data_loader), f1_score(y_true_accumulator, y_pred_accumulator), accuracy_score(y_true_accumulator, y_pred_accumulator)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T18:44:07.00824Z","iopub.status.busy":"2023-11-01T18:44:07.007934Z","iopub.status.idle":"2023-11-01T18:44:07.034722Z","shell.execute_reply":"2023-11-01T18:44:07.033788Z","shell.execute_reply.started":"2023-11-01T18:44:07.008214Z"},"trusted":true},"outputs":[],"source":["def test_fn2(data_loader,model, device):\n","    model.eval()\n","    final_loss = 0\n","    y_true_accumulator = []\n","    y_pred_accumulator = []\n","    \n","    cnt = 0\n","    for data in tqdm(data_loader,total=len(data_loader)):\n","        for k,v in data.items():\n","            data[k] = v.to(device)\n","        tag, target_tag, mask, loss = model(**data)\n","#         y_true_accumulator.append(torch.flatten(mask*target_tag).detach().cpu().tolist())\n","#         y_pred_accumulator.append(torch.flatten(mask*tag).detach().cpu().tolist()) \n","        map_dict = {0 : 'O', 1 : 'B-PER', 2 : 'I-PER', 3 : 'B-ORG', 4 : 'I-ORG', 5 : 'B-LOC', 6 : 'I-LOC', 7 : 'B-MISC', 8 : 'I-MISC'}\n","        mapped_target = [map_dict[item] for item in torch.flatten(mask*target_tag).detach().cpu().tolist()]\n","        mapped_output = [map_dict[item] for item in torch.flatten(mask*tag).detach().cpu().tolist()]\n","        y_true_accumulator.append(mapped_target)\n","        y_pred_accumulator.append(mapped_output)   \n","        final_loss += loss.item()\n","        break\n","    print(y_true_accumulator)\n","    print(y_pred_accumulator)\n","        \n","    print(classification_report(y_true_accumulator, y_pred_accumulator, digits=2))\n","    return final_loss/len(data_loader), f1_score(y_true_accumulator, y_pred_accumulator), accuracy_score(y_true_accumulator, y_pred_accumulator)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T18:44:07.037734Z","iopub.status.busy":"2023-11-01T18:44:07.037447Z","iopub.status.idle":"2023-11-01T18:44:07.055965Z","shell.execute_reply":"2023-11-01T18:44:07.054911Z","shell.execute_reply.started":"2023-11-01T18:44:07.03771Z"},"trusted":true},"outputs":[],"source":["def inference(model, sentence):\n","    tokens = sentence.split(' ')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T18:44:07.057533Z","iopub.status.busy":"2023-11-01T18:44:07.057245Z","iopub.status.idle":"2023-11-01T18:45:40.316422Z","shell.execute_reply":"2023-11-01T18:45:40.315209Z","shell.execute_reply.started":"2023-11-01T18:44:07.057508Z"},"trusted":true},"outputs":[],"source":["test_dataset = EntityDataset(texts = dataset['test']['tokens'], tags = dataset['test']['ner_tags'])\n","test_data_loader = torch.utils.data.DataLoader(test_dataset,batch_size=config.VALID_BATCH_SIZE,num_workers=1)\n","_, test_f1, test_acc = test_fn(test_data_loader, model, device)\n","print(f'F1 score on test set: {test_f1}\\nAccuracy score on test set: {test_acc}')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T18:45:40.318588Z","iopub.status.busy":"2023-11-01T18:45:40.31817Z","iopub.status.idle":"2023-11-01T18:45:40.727167Z","shell.execute_reply":"2023-11-01T18:45:40.725816Z","shell.execute_reply.started":"2023-11-01T18:45:40.31855Z"},"trusted":true},"outputs":[],"source":["_, test_f12, test_acc2 = test_fn2(test_data_loader, model, device)\n","print(f'F1 score on test set: {test_f12}\\nAccuracy score on test set: {test_acc2}')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T18:45:40.730177Z","iopub.status.busy":"2023-11-01T18:45:40.729212Z","iopub.status.idle":"2023-11-01T18:45:40.825735Z","shell.execute_reply":"2023-11-01T18:45:40.824664Z","shell.execute_reply.started":"2023-11-01T18:45:40.730136Z"},"trusted":true},"outputs":[],"source":["dataset['test']['tokens'][0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-11-01T18:45:40.827575Z","iopub.status.busy":"2023-11-01T18:45:40.827224Z","iopub.status.idle":"2023-11-01T18:45:40.885198Z","shell.execute_reply":"2023-11-01T18:45:40.884173Z","shell.execute_reply.started":"2023-11-01T18:45:40.827531Z"},"trusted":true},"outputs":[],"source":["dataset['test']['ner_tags'][0]"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":50445,"sourceId":94327,"sourceType":"datasetVersion"}],"dockerImageVersionId":30558,"isGpuEnabled":true,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
